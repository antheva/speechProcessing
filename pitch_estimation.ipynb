{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M3.wav', 'M1.wav', 'F1.wav', 'F5.wav', 'F4.wav', 'M2.wav', 'M5.wav', 'F2.wav', 'F3.wav', 'M4.wav']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "from types import SimpleNamespace\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input/test\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def autocorr_hs_method(frame, sfreq, threshold=0.49, fmin=50, fmax=400):\n",
    "    \"\"\"Estimate pitch using autocorrelation and harmonic summation in frequency domain\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate autocorrelation using scipy correlate\n",
    "    frame = frame.astype(np.float)\n",
    "    frame -= frame.mean()\n",
    "    amax = np.abs(frame).max()\n",
    "    if amax > 0:\n",
    "        frame /= amax\n",
    "    else:\n",
    "        return 0\n",
    " \n",
    "    #center clipping on the single frame\n",
    "    cl = 0.1  #set center clipping threshold to 10% of max\n",
    "    for i in range(len(frame)):\n",
    "        if frame[i] >= cl:\n",
    "            frame[i] = frame[i] - cl\n",
    "        elif frame[i] <= -cl:\n",
    "            frame[i] = frame[i] + cl\n",
    "        else: frame[i] = 0\n",
    "\n",
    "    c = signal.correlate(frame, frame)\n",
    "    c = c[len(c)//2:]\n",
    "    \n",
    "    # Find the first minimum\n",
    "    dc = np.diff(c)\n",
    "    rmin = np.where(dc > 0)[0]\n",
    "    if len(rmin) > 0:\n",
    "        rmin1 = rmin[0]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    # Find the next peak\n",
    "    peak = np.argmax(c[rmin1:]) + rmin1\n",
    "    rmax = c[peak]/c[0]\n",
    "    f0 = sfreq / peak\n",
    "    \n",
    "    dft_points = sfreq*10  #0.1 precision in freq\n",
    "    dft = np.fft.fft(frame, dft_points)\n",
    "    \n",
    "    #tuning the returned frequency with the harmonic summation\n",
    "    cand = int(round(f0/(sfreq/dft_points)))\n",
    "    for i in range(-10, 11):    #-1Hz/+1Hz\n",
    "        harm_sum = 0\n",
    "        for j in range(1,4):  #sum 3 harmonics\n",
    "            harm_sum += dft[((cand+i)*j)%dft_points]\n",
    "    \n",
    "    f0 = (cand+(np.argmax(harm_sum)-15))*(sfreq/dft_points)   #final freq is the one with the highest harmonic sum\n",
    "\n",
    "    if rmax > threshold and f0 >= fmin and f0 <= fmax:\n",
    "        return f0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "0c7be69d4071f45f46430daf4015fa8c1145d4da"
   },
   "outputs": [],
   "source": [
    "class Counters:\n",
    "    def __init__(self, gross_threshold=0.2):\n",
    "        self.num_voiced = 0\n",
    "        self.num_unvoiced = 0\n",
    "        self.num_voiced_unvoiced = 0\n",
    "        self.num_unvoiced_voiced = 0\n",
    "        self.num_voiced_voiced = 0\n",
    "        self.num_gross_errors = 0\n",
    "        self.fine_error = 0\n",
    "        self.e2 = 0\n",
    "        self.gross_threshold = gross_threshold\n",
    "        self.nfiles = 0\n",
    "\n",
    "    def add(self, other):\n",
    "        if other is not None:\n",
    "            self.num_voiced += other.num_voiced\n",
    "            self.num_unvoiced += other.num_unvoiced\n",
    "            self.num_voiced_unvoiced += other.num_voiced_unvoiced\n",
    "            self.num_unvoiced_voiced += other.num_unvoiced_voiced\n",
    "            self.num_voiced_voiced += other.num_voiced_voiced\n",
    "            self.num_gross_errors += other.num_gross_errors\n",
    "            self.fine_error += other.fine_error\n",
    "            self.e2 += other.e2\n",
    "            self.nfiles += 1\n",
    "\n",
    "    def __repr__(self):\n",
    "        nframes = self.num_voiced + self.num_unvoiced\n",
    "        if self.nfiles > 0:\n",
    "            self.fine_error /= self.nfiles\n",
    "        str = [\n",
    "            f\"Num. frames:\\t{self.num_unvoiced + self.num_voiced} = {self.num_unvoiced} unvoiced + {self.num_voiced} voiced\",\n",
    "            f\"Unvoiced frames as voiced:\\t{self.num_unvoiced_voiced}/{self.num_unvoiced} ({100*self.num_unvoiced_voiced/self.num_unvoiced:.2f}%)\",\n",
    "            f\"Voiced frames as unvoiced:\\t{self.num_voiced_unvoiced}/{self.num_voiced} ({100*self.num_voiced_unvoiced/self.num_voiced:.2f}%)\",\n",
    "            f\"Gross voiced errors (>{100*self.gross_threshold}%):\\t{self.num_gross_errors}/{self.num_voiced_voiced} ({100*self.num_gross_errors/self.num_voiced_voiced:.2f}%)\",\n",
    "            f\"MSE of fine errors:\\t{100*self.fine_error:.2f}%\",\n",
    "            f\"RMSE:\\t{np.sqrt(self.e2/nframes):.2f}\"\n",
    "        ]\n",
    "        return  '\\n'.join(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "e9870d63a5eb733ef6b98f3305b3c2634608bf3f"
   },
   "outputs": [],
   "source": [
    "def compare(fref, pitch):\n",
    "    vref = np.loadtxt(fref)\n",
    "    vtest = np.array(pitch)\n",
    "\n",
    "    diff_frames = len(vref) - len(vtest)\n",
    "    if abs(diff_frames) > 5:\n",
    "        print(f\"Error: number of frames in ref ({len(vref)}) != number of frames in test ({len(vtest)})\")\n",
    "        return None\n",
    "    elif diff_frames > 0:\n",
    "        vref = np.resize(vref, vtest.shape)\n",
    "    elif diff_frames < 0:\n",
    "        vtest = np.resize(vtest, vref.shape)\n",
    "\n",
    "    counters = Counters()\n",
    "    counters.num_voiced = np.count_nonzero(vref)\n",
    "    counters.num_unvoiced = len(vref) - counters.num_voiced\n",
    "    counters.num_unvoiced_voiced = np.count_nonzero(np.logical_and(vref == 0, vtest != 0))\n",
    "    counters.num_voiced_unvoiced = np.count_nonzero(np.logical_and(vref != 0, vtest == 0))\n",
    "\n",
    "    voiced_voiced = np.logical_and(vref != 0, vtest != 0)\n",
    "    counters.num_voiced_voiced = np.count_nonzero(voiced_voiced)\n",
    "\n",
    "    f = np.absolute(vref[voiced_voiced] - vtest[voiced_voiced])/vref[voiced_voiced]\n",
    "    gross_errors = f > counters.gross_threshold\n",
    "    counters.num_gross_errors = np.count_nonzero(gross_errors)\n",
    "    fine_errors = np.logical_not(gross_errors)\n",
    "    counters.fine_error = np.sqrt(np.square(f[fine_errors]).mean())\n",
    "    counters.e2 = np.square(vref - vtest).sum()\n",
    "\n",
    "    return counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "37f3e70917faeb9e5f47d1d53b910ce07bc944a3"
   },
   "outputs": [],
   "source": [
    "def wav2f0(options, gui):\n",
    "    fs = open(options.submission, 'w') if options.submission is not None else None\n",
    "    totalCounters = Counters()\n",
    "    with open(gui) as f:\n",
    "        if fs is not None:\n",
    "            print('id,frequency', file=fs)\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "            filename = os.path.join(options.datadir, line + \".wav\")\n",
    "            f0ref_filename = os.path.join(options.datadir, line + \".f0ref\")\n",
    "            print(\"Processing:\", filename)\n",
    "            sfreq, data = wavfile.read(filename)\n",
    "            nsamples = len(data)\n",
    "\n",
    "            \n",
    "            #PREPROCESSING\n",
    "            #lowpass filter\n",
    "            fh = 1000 #cut off freq\n",
    "            b, a = signal.ellip(5, 3, 40, fh / (sfreq / 2), 'low')\n",
    "            data = signal.filtfilt(b, a, data)\n",
    "            \n",
    "            \n",
    "            #center clipping on the entire data\n",
    "            tmp = data.copy()\n",
    "            for i in range(int(len(data)*0.03)):    #delete 3% of the max samples for setting the clipping threshold\n",
    "                clip = np.max(tmp)                  #to avoid a too large number due to unexpected peaks\n",
    "                n = np.argmax(tmp)\n",
    "                tmp[n] = 0\n",
    "                \n",
    "            \n",
    "            cl = 0.05*clip  #set center clipping threshold to 5% of previously found value\n",
    "            for i in range(len(data)):\n",
    "                if data[i] >= cl:\n",
    "                    data[i] = data[i] - cl\n",
    "                elif data[i] <= -cl:\n",
    "                    data[i] = data[i] + cl\n",
    "                else: data[i] = 0\n",
    "    \n",
    "            # From miliseconds to samples\n",
    "            ns_windowlength = int(round((options.windowlength * sfreq) / 1000))\n",
    "            ns_frameshift = int(round((options.frameshift * sfreq) / 1000))\n",
    "            ns_left_padding = int(round((options.left_padding * sfreq) / 1000))\n",
    "            ns_right_padding = int(round((options.right_padding * sfreq) / 1000))\n",
    "            pitch = []\n",
    "            \n",
    "            for id, ini in enumerate(range(-ns_left_padding, nsamples - ns_windowlength + ns_right_padding + 1, ns_frameshift)):\n",
    "                first_sample = max(0, ini)\n",
    "                last_sample = min(nsamples, ini + ns_windowlength)\n",
    "                frame = data[first_sample:last_sample]\n",
    "                f0 = autocorr_hs_method(frame, sfreq)\n",
    "                pitch.append(f0)\n",
    "               \n",
    "            #POST PROCESSING\n",
    "            pitch = signal.medfilt(pitch, 3)  #median filter\n",
    "            \n",
    "            #delete outliers (greater than 3.5 times the lowest estimated pitch)\n",
    "            pit = [f for f in pitch if f!=0]\n",
    "            for i in range(len(pitch)):\n",
    "                if (pitch[i] > 3.5*np.min(pit)):\n",
    "                    pitch[i] = 0\n",
    "            \n",
    "            for i in range(len(pitch)):\n",
    "                if fs is not None:\n",
    "                    print(line + '_' + str(i) + ',', pitch[i], file=fs)\n",
    "                          \n",
    "            if os.path.isfile(f0ref_filename):\n",
    "                counters = compare(f0ref_filename, pitch)\n",
    "                totalCounters.add(counters)\n",
    "\n",
    "    if totalCounters.num_voiced + totalCounters.num_unvoiced > 0:\n",
    "        print(\"### Summary\")\n",
    "        print(totalCounters)\n",
    "        print(\"-------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f611c950eeb79b40456612db424113d5837ac9ba",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ../input/fda_ue/rl001.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/opt/conda/lib/python3.6/site-packages/scipy/signal/signaltools.py:491: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return x[reverse].conj()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ../input/fda_ue/rl002.wav\n",
      "Processing: ../input/fda_ue/rl003.wav\n",
      "Processing: ../input/fda_ue/rl004.wav\n",
      "Processing: ../input/fda_ue/rl005.wav\n",
      "Processing: ../input/fda_ue/rl006.wav\n",
      "Processing: ../input/fda_ue/rl007.wav\n",
      "Processing: ../input/fda_ue/rl008.wav\n",
      "Processing: ../input/fda_ue/rl009.wav\n",
      "Processing: ../input/fda_ue/rl010.wav\n",
      "Processing: ../input/fda_ue/rl011.wav\n",
      "Processing: ../input/fda_ue/rl012.wav\n",
      "Processing: ../input/fda_ue/rl013.wav\n",
      "Processing: ../input/fda_ue/rl014.wav\n",
      "Processing: ../input/fda_ue/rl015.wav\n",
      "Processing: ../input/fda_ue/rl016.wav\n",
      "Processing: ../input/fda_ue/rl017.wav\n",
      "Processing: ../input/fda_ue/rl018.wav\n",
      "Processing: ../input/fda_ue/rl019.wav\n",
      "Processing: ../input/fda_ue/rl020.wav\n",
      "Processing: ../input/fda_ue/rl021.wav\n",
      "Processing: ../input/fda_ue/rl022.wav\n",
      "Processing: ../input/fda_ue/rl023.wav\n",
      "Processing: ../input/fda_ue/rl024.wav\n",
      "Processing: ../input/fda_ue/rl025.wav\n",
      "Processing: ../input/fda_ue/rl026.wav\n",
      "Processing: ../input/fda_ue/rl027.wav\n",
      "Processing: ../input/fda_ue/rl028.wav\n",
      "Processing: ../input/fda_ue/rl029.wav\n",
      "Processing: ../input/fda_ue/rl030.wav\n",
      "Processing: ../input/fda_ue/rl031.wav\n",
      "Processing: ../input/fda_ue/rl032.wav\n",
      "Processing: ../input/fda_ue/rl033.wav\n",
      "Processing: ../input/fda_ue/rl034.wav\n",
      "Processing: ../input/fda_ue/rl035.wav\n",
      "Processing: ../input/fda_ue/rl036.wav\n",
      "Processing: ../input/fda_ue/rl037.wav\n",
      "Processing: ../input/fda_ue/rl038.wav\n",
      "Processing: ../input/fda_ue/rl039.wav\n",
      "Processing: ../input/fda_ue/rl040.wav\n",
      "Processing: ../input/fda_ue/rl041.wav\n",
      "Processing: ../input/fda_ue/rl042.wav\n",
      "Processing: ../input/fda_ue/rl043.wav\n",
      "Processing: ../input/fda_ue/rl044.wav\n",
      "Processing: ../input/fda_ue/rl045.wav\n",
      "Processing: ../input/fda_ue/rl046.wav\n",
      "Processing: ../input/fda_ue/rl047.wav\n",
      "Processing: ../input/fda_ue/rl048.wav\n",
      "Processing: ../input/fda_ue/rl049.wav\n",
      "Processing: ../input/fda_ue/rl050.wav\n",
      "Processing: ../input/fda_ue/sb001.wav\n",
      "Processing: ../input/fda_ue/sb002.wav\n",
      "Processing: ../input/fda_ue/sb003.wav\n",
      "Processing: ../input/fda_ue/sb004.wav\n",
      "Processing: ../input/fda_ue/sb005.wav\n",
      "Processing: ../input/fda_ue/sb006.wav\n",
      "Processing: ../input/fda_ue/sb007.wav\n",
      "Processing: ../input/fda_ue/sb008.wav\n",
      "Processing: ../input/fda_ue/sb009.wav\n",
      "Processing: ../input/fda_ue/sb010.wav\n",
      "Processing: ../input/fda_ue/sb011.wav\n",
      "Processing: ../input/fda_ue/sb012.wav\n",
      "Processing: ../input/fda_ue/sb013.wav\n",
      "Processing: ../input/fda_ue/sb014.wav\n",
      "Processing: ../input/fda_ue/sb015.wav\n",
      "Processing: ../input/fda_ue/sb016.wav\n",
      "Processing: ../input/fda_ue/sb017.wav\n",
      "Processing: ../input/fda_ue/sb018.wav\n",
      "Processing: ../input/fda_ue/sb019.wav\n",
      "Processing: ../input/fda_ue/sb020.wav\n",
      "Processing: ../input/fda_ue/sb021.wav\n",
      "Processing: ../input/fda_ue/sb022.wav\n",
      "Processing: ../input/fda_ue/sb023.wav\n",
      "Processing: ../input/fda_ue/sb024.wav\n",
      "Processing: ../input/fda_ue/sb025.wav\n",
      "Processing: ../input/fda_ue/sb026.wav\n",
      "Processing: ../input/fda_ue/sb027.wav\n",
      "Processing: ../input/fda_ue/sb028.wav\n",
      "Processing: ../input/fda_ue/sb029.wav\n",
      "Processing: ../input/fda_ue/sb030.wav\n",
      "Processing: ../input/fda_ue/sb031.wav\n",
      "Processing: ../input/fda_ue/sb032.wav\n",
      "Processing: ../input/fda_ue/sb033.wav\n",
      "Processing: ../input/fda_ue/sb034.wav\n",
      "Processing: ../input/fda_ue/sb035.wav\n",
      "Processing: ../input/fda_ue/sb036.wav\n",
      "Processing: ../input/fda_ue/sb037.wav\n",
      "Processing: ../input/fda_ue/sb038.wav\n",
      "Processing: ../input/fda_ue/sb039.wav\n",
      "Processing: ../input/fda_ue/sb040.wav\n",
      "Processing: ../input/fda_ue/sb041.wav\n",
      "Processing: ../input/fda_ue/sb042.wav\n",
      "Processing: ../input/fda_ue/sb043.wav\n",
      "Processing: ../input/fda_ue/sb044.wav\n",
      "Processing: ../input/fda_ue/sb045.wav\n",
      "Processing: ../input/fda_ue/sb046.wav\n",
      "Processing: ../input/fda_ue/sb047.wav\n",
      "Processing: ../input/fda_ue/sb048.wav\n",
      "Processing: ../input/fda_ue/sb049.wav\n",
      "Processing: ../input/fda_ue/sb050.wav\n",
      "### Summary\n",
      "Num. frames:\t22140 = 13916 unvoiced + 8224 voiced\n",
      "Unvoiced frames as voiced:\t370/13916 (2.66%)\n",
      "Voiced frames as unvoiced:\t950/8224 (11.55%)\n",
      "Gross voiced errors (>20.0%):\t30/7274 (0.41%)\n",
      "MSE of fine errors:\t2.57%\n",
      "RMSE:\t43.96\n",
      "-------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fda_ue_options = SimpleNamespace(\n",
    "    windowlength=32, frameshift=15, left_padding=16, right_padding=16, datadir='../input', submission=None)\n",
    "wav2f0(fda_ue_options, '../input/fda_ue.gui')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "74599d24c27013ae1a90007812b76e9dc576a903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ../input/test/F1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/opt/conda/lib/python3.6/site-packages/scipy/signal/signaltools.py:491: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return x[reverse].conj()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ../input/test/F2.wav\n",
      "Processing: ../input/test/F3.wav\n",
      "Processing: ../input/test/F4.wav\n",
      "Processing: ../input/test/F5.wav\n",
      "Processing: ../input/test/M1.wav\n",
      "Processing: ../input/test/M2.wav\n",
      "Processing: ../input/test/M3.wav\n",
      "Processing: ../input/test/M4.wav\n",
      "Processing: ../input/test/M5.wav\n"
     ]
    }
   ],
   "source": [
    "test_options = SimpleNamespace(\n",
    "    windowlength=26.5, frameshift=10, left_padding=13.25, right_padding=7, datadir='../input/test', submission='submission.csv')\n",
    "wav2f0(test_options, '../input/test.gui')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "6e4503a6e9af49b2dc9c2ad8b9f0608582212249"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
